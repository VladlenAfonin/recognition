{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a40530a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "from collections import namedtuple\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "88973d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Label, Corresponding model).\n",
    "LabeledModel = namedtuple('LabeledModel', ['label', 'model'])\n",
    "\n",
    "# (Label, Path to files of that label).\n",
    "LabeledPaths = namedtuple('LabeledPaths', ['label', 'paths'])\n",
    "\n",
    "# (Label, scoring resut for given label).\n",
    "LabeledResult = namedtuple('LabeledResult', ['label', 'score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "128aea52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_paths(paths_file: str, prefix: str='',\n",
    "                   name_stop_symb: str='-') -> list[LabeledPaths]:\n",
    "    \"\"\"Construct a list of Examples (label, filepaths) from a given file\n",
    "    containing filepaths separated by whitespaces.\n",
    "    \"\"\"\n",
    "    \n",
    "    # To be a list of LabeledPaths.\n",
    "    training_set = []\n",
    "    with open(paths_file) as file:\n",
    "        \n",
    "        # After first read get label and first path.\n",
    "        while line := file.readline().rstrip():\n",
    "                \n",
    "            # Set part of the path before `name_stop_symb' as label.\n",
    "            label = line.split(name_stop_symb)[0]\n",
    "            ex = LabeledPaths(label, [os.path.join(prefix, line)])\n",
    "\n",
    "            # Continue to read paths until there's no left.\n",
    "            while line := file.readline().rstrip():\n",
    "                ex.paths.append(os.path.join(prefix, line))\n",
    "\n",
    "            training_set.append(ex)\n",
    "    \n",
    "    return training_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "674a3e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(utterance: np.ndarray, sr: int, n_mfccs: int=20):\n",
    "    \"\"\"Get features from a given librosa-returned array. Returns n_mfccs * 3\n",
    "    features: MFCC, their 1st and 2nd differences concatenated horizontally.\n",
    "    \"\"\"\n",
    "    \n",
    "    mfccs  = librosa.feature.mfcc(utterance, sr, n_mfcc=n_mfccs)\n",
    "    mfccs1 = librosa.feature.delta(mfccs)\n",
    "    mfccs2 = librosa.feature.delta(mfccs, order=2)\n",
    "    \n",
    "    # Librosa returns features in shape (n_mfcc, ...). We want mfccs to\n",
    "    # be \"columns\" in our dataset => we transpose them.\n",
    "    features = np.hstack((mfccs.T, mfccs1.T, mfccs2.T))\n",
    "    return features\n",
    "\n",
    "def get_features_path(filepaths: list[str], n_mfccs: int=20) -> np.ndarray:\n",
    "    \"\"\"Gets features from given files. Uses get_features for feature-extraction.\n",
    "    \"\"\"\n",
    "    \n",
    "    features = np.empty((0, n_mfccs * 3))\n",
    "    for path in filepaths:\n",
    "        utt, sr = librosa.load(path)\n",
    "        utt = librosa.util.normalize(utt)\n",
    "        features_utt = get_features(utt, sr, n_mfccs=n_mfccs)\n",
    "        \n",
    "        features = np.vstack((features, features_utt))\n",
    "    \n",
    "    return features\n",
    "\n",
    "def map_adapt(ubm, X, max_iter=100, r=16):\n",
    "    \n",
    "    gmm = copy.deepcopy(ubm)\n",
    "    \n",
    "    for _ in range(max_iter):\n",
    "        n = np.sum(gmm.predict_proba(X), axis=0).reshape(-1, 1) # (K, 1)\n",
    "        X_tilde = (1 / n) * gmm.predict_proba(X).T.dot(X) # (K, F)\n",
    "        alpha = (n / (n + r)).reshape(-1, 1) # (K, 1)\n",
    "        gmm.means_ = alpha * X_tilde + (1 - alpha) * gmm.means_\n",
    "    \n",
    "    return gmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c1c6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_models(ubm: GaussianMixture, examples: list[LabeledPaths]) -> list[LabeledModel]:\n",
    "    \"\"\"Create and train models for a given set of LabeledPaths (label, filepaths)\n",
    "    created via get_data_paths function. Returns labeled models of type\n",
    "    (label, model). Labels are preserved from corresponding LabeledPaths.\n",
    "    \"\"\"\n",
    "    \n",
    "    # To be a list of labeled models.\n",
    "    labeled_models = []\n",
    "    for example in examples:\n",
    "        \n",
    "        # Get features from files.\n",
    "        features = get_features_path(example.paths)\n",
    "        \n",
    "        # Create and train GMM using MAP-adaptation.\n",
    "        gmm = map_adapt(ubm, features)\n",
    "        \n",
    "        # Add generated model to the list.\n",
    "        lm = LabeledModel(example.label, gmm)\n",
    "        labeled_models.append(lm)\n",
    "\n",
    "    return labeled_models\n",
    "\n",
    "def test_models(test_examples:  list[LabeledPaths],\n",
    "                labeled_models: list[LabeledModel]) -> float:\n",
    "    \"\"\"Test models and return accuracy. Takes list of LabeledPaths (label, filepaths)\n",
    "    and tests labeled models (label, model) against these examples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # To be a list of results: Trues and Falses.\n",
    "    results = []\n",
    "    for test_example in test_examples:\n",
    "        \n",
    "        # Extract features for given speakers' filepaths.\n",
    "        features = get_features_path(test_example.paths)\n",
    "        \n",
    "        # Get results for given speaker on all models in labeled_models.\n",
    "        labeled_results = []\n",
    "        for labeled_model in labeled_models:\n",
    "            res = LabeledResult(labeled_model.label,\n",
    "                                labeled_model.model.score(features))\n",
    "            labeled_results.append(res)\n",
    "        \n",
    "        # Get index of a highest score and make corresponding label a prediction.\n",
    "        scores_only = np.array([lr.score for lr in labeled_results], dtype=float)\n",
    "        index = np.argmax(scores_only)\n",
    "        label_pred = labeled_results[index].label\n",
    "        \n",
    "        # Check if prediction if correct and store result in results.\n",
    "        results.append(label_pred == test_example.label)\n",
    "    \n",
    "    return sum(results) / len(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08be15d0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd1a6ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "female_dir_ubm = './dataset_supervectors/train_data/UBM/female'\n",
    "male_dir_ubm   = './dataset_supervectors/train_data/UBM/male'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6363b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_ubm = np.empty((0, 60))\n",
    "for filepath in os.listdir(female_dir_ubm):\n",
    "    utt, sr = librosa.load(os.path.join(female_dir_ubm, filepath))\n",
    "    utt = librosa.util.normalize(utt)\n",
    "    features_utt = get_features(utt, sr)\n",
    "    features_ubm = np.vstack((features_ubm, features_utt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2a796d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filepath in os.listdir(male_dir_ubm):\n",
    "    utt, sr = librosa.load(os.path.join(male_dir_ubm, filepath))\n",
    "    utt = librosa.util.normalize(utt)\n",
    "    features_utt = get_features(utt, sr)\n",
    "    features_ubm = np.vstack((features_ubm, features_utt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10febc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianMixture(covariance_type='diag', max_iter=200, n_components=64, n_init=3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ubm = GaussianMixture(n_components=64,\n",
    "                      covariance_type='diag',\n",
    "                      n_init=3,\n",
    "                      max_iter=200)\n",
    "\n",
    "ubm.fit(features_ubm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19df9624",
   "metadata": {},
   "source": [
    "## Train other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7018bd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = './dataset_vr'\n",
    "train_paths_file = './train_data_paths.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b4edb63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_set = get_data_paths(train_paths_file, prefix=train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1511aa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = get_models(ubm, training_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f6ba1b",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d09f0589",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_paths_file = './test_data_paths.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc36572e",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_set = get_data_paths(test_paths_file, prefix=train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c17585c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models(testing_set, models)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
